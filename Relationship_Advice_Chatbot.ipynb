{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2j09gVq_oD3"
      },
      "source": [
        "### Install Required Packages\n",
        "\n",
        "We begin by installing and upgrading the required libraries: `openai`, `gradio`, `textblob`, and `matplotlib`. These are necessary for generating responses, building the UI, analyzing sentiment, and logging conversations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XZt0Alv5xhSQ",
        "outputId": "d9064eae-a309-47d1-dcfa-5799fda73999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install --upgrade --quiet openai==0.28 gradio textblob matplotlib\n",
        "!python -m textblob.download_corpora\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-vVV0J-_pu4"
      },
      "source": [
        "### Import Libraries & Set API Key\n",
        "\n",
        "We import the required Python libraries and load the OpenAI API key securely. Make sure your OpenAI key is stored in a safe location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI_Z5qBwxNAQ"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import openai\n",
        "import gradio as gr\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load OpenAI API key securely from Colab secrets\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get(\"openai\")\n",
        "\n",
        "# Create directory for logging chat history\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "LOG_FILE = \"logs/chat_log.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uDxpVn4_vdy"
      },
      "source": [
        "### Analyze Sentiment of User Input\n",
        "\n",
        "This function uses `TextBlob` to classify user messages into Positive, Neutral, or Negative sentiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR1_r5Wlot9P"
      },
      "outputs": [],
      "source": [
        "# Define function to analyze sentiment of user input\n",
        "def get_sentiment(text):\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0.2:\n",
        "        return \"Positive\"\n",
        "    elif polarity < -0.2:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G12Bx9Rv_yJa"
      },
      "source": [
        "### Chatbot Response Function\n",
        "\n",
        "This function handles the conversation flow:\n",
        "- Builds the conversation history\n",
        "- Sends a prompt to the OpenAI API\n",
        "- Analyzes sentiment of the user input\n",
        "- Logs the full conversation to `chat_log.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F5busF9ovp7"
      },
      "outputs": [],
      "source": [
        "# Define chatbot function to generate AI response, analyze sentiment, and log the interaction\n",
        "def chatbot_response(prompt, chat_history):\n",
        "    try:\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a psychologist specializing in relationships.\"}]\n",
        "        for user_input, bot_reply in chat_history:\n",
        "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        bot_reply = response.choices[0].message[\"content\"]\n",
        "        sentiment = get_sentiment(prompt)\n",
        "\n",
        "        log_entry = pd.DataFrame([{\n",
        "            \"User Message\": prompt,\n",
        "            \"Sentiment\": sentiment,\n",
        "            \"Bot Response\": bot_reply\n",
        "        }])\n",
        "\n",
        "        log_entry.to_csv(LOG_FILE, mode='a', header=not os.path.exists(LOG_FILE), index=False)\n",
        "\n",
        "        chat_history.append((prompt, bot_reply))\n",
        "        return chat_history, \"\"\n",
        "    except Exception as e:\n",
        "        return chat_history, f\"API Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p0euRAq_1FL"
      },
      "source": [
        "### Clear Chat Function\n",
        "\n",
        "Used to reset the chat history when the user presses the \"Clear Chat\" button.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW71aCIgowmm"
      },
      "outputs": [],
      "source": [
        "# Define function to clear chat history\n",
        "def clear_chat():\n",
        "    return [], []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86B9rlgw_3F7"
      },
      "source": [
        "### Launch the Chatbot Interface with Gradio\n",
        "\n",
        "We define a user-friendly interface with:\n",
        "- Chat display area\n",
        "- Text input box\n",
        "- Send and Clear buttons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "cqLX4HxP_4Fw",
        "outputId": "57a8e0e3-edfd-4df3-f1fc-00c524abdeda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-7b311a4af9dd>:5: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Your Relationship Advisor\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7c393d2f0b5ccf7b5c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://7c393d2f0b5ccf7b5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build Gradio interface for the chatbot\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## Relationship Advice Chatbot\")\n",
        "    gr.Markdown(\"Ask anything about relationships and get expert guidance from your AI psychologist.\")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Your Relationship Advisor\")\n",
        "    msg = gr.Textbox(placeholder=\"Type your message here...\", label=\"Your Message\")\n",
        "    send = gr.Button(\"Send\")\n",
        "    clear = gr.Button(\"Clear Chat\")\n",
        "    history = gr.State([])\n",
        "\n",
        "    send.click(fn=chatbot_response, inputs=[msg, history], outputs=[chatbot, msg])\n",
        "    clear.click(fn=clear_chat, outputs=[chatbot, history])\n",
        "\n",
        "app.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}